# THub V2 Production Implementation Guide

This guide provides step-by-step implementation instructions with full code diffs to make THub V2 production-ready.

## Table of Contents
1. [Phase 1: Critical Database Fixes](#phase-1-critical-database-fixes)
2. [Phase 2: API Contract Fixes](#phase-2-api-contract-fixes)
3. [Phase 3: Replace Mock Data](#phase-3-replace-mock-data)
4. [Phase 4: Analytics Integration](#phase-4-analytics-integration)
5. [Phase 5: Activity Feed Implementation](#phase-5-activity-feed-implementation)
6. [Validation Steps](#validation-steps)

---

## Phase 1: Critical Database Fixes

### 1.1 Create Missing RPC Functions

**Issue**: Three RPC functions are referenced in code but don't exist in the database:
- `array_append_unique` (signals.service.ts:207)
- `array_remove` (signals.service.ts:212)
- `get_signal_analytics` (signals.service.ts:202)

**Solution**: Create a new migration file

Create file: `/supabase/migrations/005_missing_rpc_functions.sql`

```sql
-- array_append_unique: Appends element to array only if not already present
CREATE OR REPLACE FUNCTION array_append_unique(target_array text[], new_element text)
RETURNS text[]
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  IF new_element = ANY(target_array) THEN
    RETURN target_array;
  ELSE
    RETURN array_append(target_array, new_element);
  END IF;
END;
$$;

-- array_remove: Removes all occurrences of element from array
CREATE OR REPLACE FUNCTION array_remove(target_array text[], element_to_remove text)
RETURNS text[]
LANGUAGE sql
SECURITY DEFINER
AS $$
  SELECT array_agg(elem)
  FROM unnest(target_array) AS elem
  WHERE elem != element_to_remove;
$$;

-- get_signal_analytics: Returns analytics for signals
CREATE OR REPLACE FUNCTION get_signal_analytics()
RETURNS TABLE (
  total_signals bigint,
  active_signals bigint,
  successful_signals bigint,
  failed_signals bigint,
  average_score numeric,
  average_return numeric,
  total_return numeric,
  success_rate numeric
)
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  RETURN QUERY
  SELECT
    COUNT(*)::bigint as total_signals,
    COUNT(*) FILTER (WHERE status = 'active')::bigint as active_signals,
    COUNT(*) FILTER (WHERE status = 'closed' AND actual_return > 0)::bigint as successful_signals,
    COUNT(*) FILTER (WHERE status = 'closed' AND actual_return <= 0)::bigint as failed_signals,
    ROUND(AVG(convergence_score)::numeric, 2) as average_score,
    ROUND(AVG(CASE 
      WHEN status = 'closed' AND actual_return IS NOT NULL THEN actual_return 
      ELSE NULL 
    END)::numeric, 2) as average_return,
    ROUND(SUM(CASE 
      WHEN status = 'closed' AND actual_return IS NOT NULL THEN actual_return 
      ELSE 0 
    END)::numeric, 2) as total_return,
    ROUND((COUNT(*) FILTER (WHERE status = 'closed' AND actual_return > 0)::numeric / 
           NULLIF(COUNT(*) FILTER (WHERE status = 'closed'), 0) * 100), 2) as success_rate
  FROM signals
  WHERE created_at >= NOW() - INTERVAL '30 days';
END;
$$;

-- Grant execute permissions
GRANT EXECUTE ON FUNCTION array_append_unique TO authenticated;
GRANT EXECUTE ON FUNCTION array_remove TO authenticated;
GRANT EXECUTE ON FUNCTION get_signal_analytics TO authenticated;
```

**Apply migration**:
```bash
npx supabase migration up --local
```

---

## Phase 2: API Contract Fixes

### 2.1 Fix Save/Unsave API Response

**Issue**: Client expects `{ saved: boolean }` but server returns `{ success: true }`

**Current code** in `/src/app/api/signals/[id]/save/route.ts:44`:
```typescript
return NextResponse.json({ success: true });
```

**Fix** - Update the entire route:
```typescript
import { NextRequest, NextResponse } from 'next/server';
import { withAuth } from '@/lib/auth/token-auth';
import { SignalsService } from '@/lib/services/signals.service';
import { createClient } from '@/lib/supabase/client';
import { z } from 'zod';

const paramsSchema = z.object({
  id: z.string().uuid()
});

export const PUT = withAuth(async (request: NextRequest, user) => {
  try {
    const { params } = request as any;
    const { id } = paramsSchema.parse(params);
    
    const supabase = createClient();
    const signalsService = new SignalsService(supabase);
    
    // Save the signal
    await signalsService.saveSignal(id, user.id);
    
    // Return the expected format
    return NextResponse.json({ saved: true });
  } catch (error) {
    if (error instanceof z.ZodError) {
      return NextResponse.json(
        { error: 'Invalid signal ID' },
        { status: 400 }
      );
    }
    
    console.error('Error saving signal:', error);
    return NextResponse.json(
      { error: 'Failed to save signal' },
      { status: 500 }
    );
  }
});

export const DELETE = withAuth(async (request: NextRequest, user) => {
  try {
    const { params } = request as any;
    const { id } = paramsSchema.parse(params);
    
    const supabase = createClient();
    const signalsService = new SignalsService(supabase);
    
    // Unsave the signal
    await signalsService.unsaveSignal(id, user.id);
    
    // Return the expected format
    return NextResponse.json({ saved: false });
  } catch (error) {
    if (error instanceof z.ZodError) {
      return NextResponse.json(
        { error: 'Invalid signal ID' },
        { status: 400 }
      );
    }
    
    console.error('Error unsaving signal:', error);
    return NextResponse.json(
      { error: 'Failed to unsave signal' },
      { status: 500 }
    );
  }
});
```

---

## Phase 3: Replace Mock Data

### 3.1 Remove Mock Signal Enrichment

**Issue**: Signal enrichment uses random mock data instead of real market data

**Current code** in `/src/lib/services/signals.service.ts:272-293`:
```typescript
// For now, we'll add mock data
return signals.map(signal => mapDbSignalToUI(signal, {
  company_name: this.getCompanyName(signal.symbol),
  price_change_24h: this.generatePriceChange(),
  price_change_percent_24h: this.generatePriceChangePercent(),
  volume_24h: this.generateVolume(),
  market_cap: this.generateMarketCap(),
  price_history: this.generatePriceHistory(signal.current_price || 100)
}))
```

**Fix** - Replace the entire `enrichSignals` method:
```typescript
private async enrichSignals(signals: DbSignal[]): Promise<Signal[]> {
  if (signals.length === 0) return [];
  
  try {
    // Fetch real market data for all signals in parallel
    const symbols = signals.map(s => s.symbol);
    const marketDataPromises = symbols.map(async (symbol) => {
      try {
        // Get real-time quote data
        const quote = await this.eodhd.getQuote(symbol);
        
        // Get intraday data for price history (last 24 hours)
        const endDate = new Date();
        const startDate = new Date(endDate.getTime() - 24 * 60 * 60 * 1000);
        const intraday = await this.eodhd.getIntraday(
          symbol,
          '1h',
          startDate,
          endDate
        );
        
        return { symbol, quote, intraday };
      } catch (error) {
        console.error(`Failed to fetch market data for ${symbol}:`, error);
        // Return null for failed fetches
        return { symbol, quote: null, intraday: null };
      }
    });
    
    const marketDataResults = await Promise.all(marketDataPromises);
    
    // Create a map for quick lookup
    const marketDataMap = new Map(
      marketDataResults.map(result => [result.symbol, result])
    );
    
    // Map signals with real data
    return signals.map(signal => {
      const marketData = marketDataMap.get(signal.symbol);
      
      if (marketData?.quote) {
        const { quote, intraday } = marketData;
        
        // Calculate real price changes
        const price_change_24h = quote.close - quote.previousClose;
        const price_change_percent_24h = (price_change_24h / quote.previousClose) * 100;
        
        // Create price history from intraday data
        const price_history = intraday?.data?.map(bar => ({
          time: new Date(bar.datetime).toISOString(),
          value: bar.close
        })) || [];
        
        return mapDbSignalToUI(signal, {
          company_name: quote.name || this.getCompanyName(signal.symbol),
          price_change_24h,
          price_change_percent_24h,
          volume_24h: quote.volume || 0,
          market_cap: quote.marketCap || 0,
          price_history
        });
      }
      
      // Fallback for failed fetches - use conservative defaults
      return mapDbSignalToUI(signal, {
        company_name: this.getCompanyName(signal.symbol),
        price_change_24h: 0,
        price_change_percent_24h: 0,
        volume_24h: 0,
        market_cap: 0,
        price_history: []
      });
    });
  } catch (error) {
    console.error('Error enriching signals:', error);
    // Return signals without enrichment on complete failure
    return signals.map(signal => mapDbSignalToUI(signal, {
      company_name: this.getCompanyName(signal.symbol),
      price_change_24h: 0,
      price_change_percent_24h: 0,
      volume_24h: 0,
      market_cap: 0,
      price_history: []
    }));
  }
}
```

**Also add** these imports at the top:
```typescript
import { EODHDService } from './eodhd.service';
```

**And update** the constructor:
```typescript
private eodhd: EODHDService;

constructor(
  private supabase: SupabaseClient,
  options?: {
    cache?: CacheService;
    rateLimiter?: RateLimiter;
    eodhd?: EODHDService;
  }
) {
  this.cache = options?.cache || getCacheService();
  this.rateLimiter = options?.rateLimiter || getRateLimiter();
  this.eodhd = options?.eodhd || new EODHDService({ 
    cache: this.cache,
    rateLimiter: this.rateLimiter 
  });
}
```

---

## Phase 4: Analytics Integration

### 4.1 Connect Dashboard Stats to Real Analytics

**Issue**: Dashboard stats are hardcoded instead of using the analytics endpoint

**Current code** in `/src/lib/hooks/use-market-data.ts:166-175`:
```typescript
// TODO: Connect to real analytics service
// For now, return computed stats based on recent signals
const stats: DashboardStats = {
  active_signals: 24,
  success_rate: 87,
  total_profit: 12450,
  avg_return: 15.3,
  change_active_signals: '+12%',
  change_success_rate: '+5%',
  change_total_profit: '+23%',
  change_avg_return: '+2.1%',
}
```

**Fix** - Replace the entire `useDashboardStats` hook:
```typescript
export function useDashboardStats() {
  return useQuery({
    queryKey: queryKeys.dashboard.stats(),
    queryFn: async () => {
      const response = await fetch('/api/signals/analytics');
      
      if (!response.ok) {
        throw new Error('Failed to fetch dashboard stats');
      }
      
      const analytics = await response.json();
      
      // Transform analytics response to DashboardStats format
      const stats: DashboardStats = {
        active_signals: analytics.active_signals || 0,
        success_rate: analytics.success_rate || 0,
        total_profit: analytics.total_return || 0,
        avg_return: analytics.average_return || 0,
        // Calculate week-over-week changes (would need historical data)
        // For now, return static placeholders until we implement historical tracking
        change_active_signals: '+0%',
        change_success_rate: '+0%', 
        change_total_profit: '+0%',
        change_avg_return: '+0%',
      };
      
      return stats;
    },
    staleTime: 60 * 1000, // 1 minute
    gcTime: 5 * 60 * 1000, // 5 minutes
    retry: 2,
  });
}
```

### 4.2 Add Historical Analytics Tracking

To properly calculate week-over-week changes, create a new migration:

Create file: `/supabase/migrations/006_analytics_history.sql`

```sql
-- Create analytics history table
CREATE TABLE analytics_history (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL,
  period_end TIMESTAMP WITH TIME ZONE NOT NULL,
  total_signals BIGINT NOT NULL,
  active_signals BIGINT NOT NULL,  
  successful_signals BIGINT NOT NULL,
  failed_signals BIGINT NOT NULL,
  average_score NUMERIC(5,2),
  average_return NUMERIC(10,2),
  total_return NUMERIC(15,2),
  success_rate NUMERIC(5,2)
);

-- Index for efficient querying
CREATE INDEX idx_analytics_history_period ON analytics_history(period_end DESC);

-- Function to capture weekly snapshot
CREATE OR REPLACE FUNCTION capture_analytics_snapshot()
RETURNS void
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  INSERT INTO analytics_history (
    period_end,
    total_signals,
    active_signals,
    successful_signals,
    failed_signals,
    average_score,
    average_return,
    total_return,
    success_rate
  )
  SELECT 
    NOW() as period_end,
    total_signals,
    active_signals,
    successful_signals,
    failed_signals,
    average_score,
    average_return,
    total_return,
    success_rate
  FROM get_signal_analytics();
END;
$$;

-- Enhanced analytics function with week-over-week changes
CREATE OR REPLACE FUNCTION get_signal_analytics_with_changes()
RETURNS TABLE (
  total_signals bigint,
  active_signals bigint,
  successful_signals bigint,
  failed_signals bigint,
  average_score numeric,
  average_return numeric,
  total_return numeric,
  success_rate numeric,
  change_active_signals text,
  change_success_rate text,
  change_total_return text,
  change_average_return text
)
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  current_stats RECORD;
  last_week_stats RECORD;
  change_active numeric;
  change_rate numeric;
  change_return numeric;
  change_avg numeric;
BEGIN
  -- Get current stats
  SELECT * INTO current_stats FROM get_signal_analytics();
  
  -- Get stats from 7 days ago
  SELECT * INTO last_week_stats
  FROM analytics_history
  WHERE period_end <= NOW() - INTERVAL '7 days'
  ORDER BY period_end DESC
  LIMIT 1;
  
  -- Calculate percentage changes
  IF last_week_stats IS NOT NULL THEN
    change_active := CASE 
      WHEN last_week_stats.active_signals > 0 
      THEN ((current_stats.active_signals - last_week_stats.active_signals)::numeric / last_week_stats.active_signals) * 100
      ELSE 0
    END;
    
    change_rate := CASE
      WHEN last_week_stats.success_rate > 0
      THEN ((current_stats.success_rate - last_week_stats.success_rate)::numeric / last_week_stats.success_rate) * 100
      ELSE 0
    END;
    
    change_return := CASE
      WHEN last_week_stats.total_return != 0
      THEN ((current_stats.total_return - last_week_stats.total_return)::numeric / ABS(last_week_stats.total_return)) * 100
      ELSE 0
    END;
    
    change_avg := CASE
      WHEN last_week_stats.average_return != 0
      THEN ((current_stats.average_return - last_week_stats.average_return)::numeric / ABS(last_week_stats.average_return)) * 100
      ELSE 0
    END;
  ELSE
    change_active := 0;
    change_rate := 0;
    change_return := 0;
    change_avg := 0;
  END IF;
  
  RETURN QUERY
  SELECT
    current_stats.total_signals,
    current_stats.active_signals,
    current_stats.successful_signals,
    current_stats.failed_signals,
    current_stats.average_score,
    current_stats.average_return,
    current_stats.total_return,
    current_stats.success_rate,
    CASE 
      WHEN change_active >= 0 THEN '+' || ROUND(change_active, 1)::text || '%'
      ELSE ROUND(change_active, 1)::text || '%'
    END as change_active_signals,
    CASE 
      WHEN change_rate >= 0 THEN '+' || ROUND(change_rate, 1)::text || '%'
      ELSE ROUND(change_rate, 1)::text || '%'
    END as change_success_rate,
    CASE 
      WHEN change_return >= 0 THEN '+' || ROUND(change_return, 1)::text || '%'
      ELSE ROUND(change_return, 1)::text || '%'
    END as change_total_return,
    CASE 
      WHEN change_avg >= 0 THEN '+' || ROUND(change_avg, 1)::text || '%'
      ELSE ROUND(change_avg, 1)::text || '%'
    END as change_average_return;
END;
$$;

-- Grant permissions
GRANT EXECUTE ON FUNCTION capture_analytics_snapshot TO authenticated;
GRANT EXECUTE ON FUNCTION get_signal_analytics_with_changes TO authenticated;
GRANT SELECT ON analytics_history TO authenticated;
```

### 4.3 Update Analytics Service

Update `/src/lib/services/signals.service.ts` to use the new function:

```typescript
async getAnalytics(): Promise<SignalAnalytics> {
  const { data, error } = await this.supabase.rpc('get_signal_analytics_with_changes')
  
  if (error) {
    console.error('Error fetching signal analytics:', error)
    throw new DatabaseError('Failed to fetch signal analytics')
  }
  
  if (!data || data.length === 0) {
    // Return default analytics if no data
    return {
      total_signals: 0,
      active_signals: 0,
      successful_signals: 0,
      failed_signals: 0,
      average_score: 0,
      average_return: 0,
      total_return: 0,
      success_rate: 0,
      change_active_signals: '+0%',
      change_success_rate: '+0%',
      change_total_return: '+0%',
      change_average_return: '+0%'
    }
  }
  
  return data[0]
}
```

---

## Phase 5: Activity Feed Implementation

### 5.1 Create Activity Tracking Table

Create file: `/supabase/migrations/007_activity_feed.sql`

```sql
-- Create activity feed table
CREATE TABLE activity_feed (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL,
  user_id UUID REFERENCES test_users(id) ON DELETE CASCADE,
  type TEXT NOT NULL CHECK (type IN ('signal', 'update', 'scan', 'success', 'error')),
  title TEXT NOT NULL,
  description TEXT,
  metadata JSONB DEFAULT '{}',
  is_public BOOLEAN DEFAULT true
);

-- Indexes for efficient querying
CREATE INDEX idx_activity_feed_created ON activity_feed(created_at DESC);
CREATE INDEX idx_activity_feed_user ON activity_feed(user_id, created_at DESC);
CREATE INDEX idx_activity_feed_public ON activity_feed(is_public, created_at DESC) WHERE is_public = true;

-- RLS policies
ALTER TABLE activity_feed ENABLE ROW LEVEL SECURITY;

-- Users can see their own activities
CREATE POLICY "Users can view own activities" ON activity_feed
  FOR SELECT
  USING (auth.uid() = user_id);

-- Everyone can see public activities
CREATE POLICY "Public activities are visible to all" ON activity_feed
  FOR SELECT
  USING (is_public = true);

-- Only system can insert activities (via service role)
CREATE POLICY "System can insert activities" ON activity_feed
  FOR INSERT
  WITH CHECK (false);

-- Function to log activity
CREATE OR REPLACE FUNCTION log_activity(
  p_user_id UUID,
  p_type TEXT,
  p_title TEXT,
  p_description TEXT DEFAULT NULL,
  p_metadata JSONB DEFAULT '{}',
  p_is_public BOOLEAN DEFAULT true
)
RETURNS UUID
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  v_activity_id UUID;
BEGIN
  INSERT INTO activity_feed (user_id, type, title, description, metadata, is_public)
  VALUES (p_user_id, p_type, p_title, p_description, p_metadata, p_is_public)
  RETURNING id INTO v_activity_id;
  
  RETURN v_activity_id;
END;
$$;

-- Grant execute permission
GRANT EXECUTE ON FUNCTION log_activity TO authenticated;

-- Trigger to log signal creation
CREATE OR REPLACE FUNCTION log_signal_activity()
RETURNS TRIGGER
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  IF TG_OP = 'INSERT' THEN
    PERFORM log_activity(
      NULL, -- System activity
      'signal',
      format('New %s signal: %s', 
        CASE 
          WHEN NEW.signal_strength = 'very_strong' THEN 'VERY STRONG'
          WHEN NEW.signal_strength = 'strong' THEN 'STRONG'
          ELSE 'MODERATE'
        END,
        NEW.symbol
      ),
      format('Convergence score: %s%%', ROUND(NEW.convergence_score, 1)),
      jsonb_build_object(
        'signal_id', NEW.id,
        'symbol', NEW.symbol,
        'convergence_score', NEW.convergence_score,
        'signal_strength', NEW.signal_strength
      ),
      true
    );
  END IF;
  
  RETURN NEW;
END;
$$;

CREATE TRIGGER signal_activity_trigger
AFTER INSERT ON signals
FOR EACH ROW
EXECUTE FUNCTION log_signal_activity();
```

### 5.2 Create Activity API Endpoint

Create file: `/src/app/api/activity/route.ts`

```typescript
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@/lib/supabase/server';
import { z } from 'zod';

const querySchema = z.object({
  limit: z.coerce.number().min(1).max(50).default(10),
  offset: z.coerce.number().min(0).default(0),
  type: z.enum(['signal', 'update', 'scan', 'success', 'error']).optional(),
});

export async function GET(request: NextRequest) {
  try {
    const searchParams = request.nextUrl.searchParams;
    const query = querySchema.parse({
      limit: searchParams.get('limit') || '10',
      offset: searchParams.get('offset') || '0',
      type: searchParams.get('type') || undefined,
    });
    
    const supabase = createClient();
    
    let dbQuery = supabase
      .from('activity_feed')
      .select('*')
      .order('created_at', { ascending: false })
      .limit(query.limit)
      .range(query.offset, query.offset + query.limit - 1);
    
    if (query.type) {
      dbQuery = dbQuery.eq('type', query.type);
    }
    
    const { data, error } = await dbQuery;
    
    if (error) {
      console.error('Error fetching activity feed:', error);
      return NextResponse.json(
        { error: 'Failed to fetch activity feed' },
        { status: 500 }
      );
    }
    
    return NextResponse.json({ data: data || [] });
  } catch (error) {
    if (error instanceof z.ZodError) {
      return NextResponse.json(
        { error: 'Invalid query parameters', details: error.errors },
        { status: 400 }
      );
    }
    
    console.error('Error in activity feed endpoint:', error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}
```

### 5.3 Create Activity Hook

Create file: `/src/lib/hooks/use-activity.ts`

```typescript
import { useQuery } from '@tanstack/react-query';
import { queryKeys } from '@/lib/query-keys';

interface Activity {
  id: string;
  created_at: string;
  type: 'signal' | 'update' | 'scan' | 'success' | 'error';
  title: string;
  description?: string;
  metadata?: Record<string, any>;
}

interface UseActivityOptions {
  limit?: number;
  type?: Activity['type'];
  enabled?: boolean;
}

export function useActivity(options: UseActivityOptions = {}) {
  const { limit = 10, type, enabled = true } = options;
  
  return useQuery({
    queryKey: queryKeys.activity.list({ limit, type }),
    queryFn: async () => {
      const params = new URLSearchParams();
      params.set('limit', limit.toString());
      if (type) params.set('type', type);
      
      const response = await fetch(`/api/activity?${params}`);
      
      if (!response.ok) {
        throw new Error('Failed to fetch activity feed');
      }
      
      const { data } = await response.json();
      return data as Activity[];
    },
    enabled,
    staleTime: 30 * 1000, // 30 seconds
    gcTime: 2 * 60 * 1000, // 2 minutes
  });
}
```

### 5.4 Update Query Keys

Add to `/src/lib/query-keys.ts`:

```typescript
export const queryKeys = {
  // ... existing keys ...
  activity: {
    all: ['activity'] as const,
    list: (filters: { limit?: number; type?: string }) => 
      [...queryKeys.activity.all, 'list', filters] as const,
  },
} as const;
```

### 5.5 Update Dashboard Activity Feed

Replace the hardcoded activity feed in `/src/app/(dashboard)/dashboard/page.tsx`:

```typescript
import { useActivity } from '@/lib/hooks/use-activity';
import { formatDistanceToNow } from 'date-fns';

const ActivityFeed = () => {
  const { data: activities, isLoading, error } = useActivity({ limit: 5 });
  
  if (error) return null; // Gracefully handle errors
  
  if (isLoading) {
    return <ActivityFeedSkeleton />;
  }
  
  if (!activities || activities.length === 0) {
    return (
      <GlassCard variant="surface" className="p-6">
        <h3 className="text-xl font-semibold text-white flex items-center gap-2 mb-4">
          <Clock className="w-5 h-5 text-violet-400" />
          Recent Activity
        </h3>
        <p className="text-gray-400 text-sm">No recent activity</p>
      </GlassCard>
    );
  }
  
  const getActivityIcon = (type: string) => {
    switch (type) {
      case 'signal':
        return 'üéØ';
      case 'update':
        return 'üìä';
      case 'scan':
        return 'üîç';
      case 'success':
        return '‚úÖ';
      default:
        return 'üìå';
    }
  };
  
  return (
    <GlassCard variant="surface" className="p-6">
      <h3 className="text-xl font-semibold text-white flex items-center gap-2 mb-4">
        <Clock className="w-5 h-5 text-violet-400" />
        Recent Activity
      </h3>
      
      <div className="space-y-3">
        {activities.map((activity, index) => (
          <motion.div
            key={activity.id}
            initial={{ opacity: 0, x: -20 }}
            animate={{ opacity: 1, x: 0 }}
            transition={{ delay: index * 0.05 }}
            className="flex items-start justify-between py-2 border-b border-gray-800 last:border-0"
          >
            <div className="flex items-start gap-3">
              <span className="text-lg">{getActivityIcon(activity.type)}</span>
              <div>
                <p className="text-sm text-gray-300">{activity.title}</p>
                {activity.description && (
                  <p className="text-xs text-gray-500 mt-1">{activity.description}</p>
                )}
              </div>
            </div>
            <span className="text-xs text-gray-500 whitespace-nowrap">
              {formatDistanceToNow(new Date(activity.created_at), { addSuffix: true })}
            </span>
          </motion.div>
        ))}
      </div>
    </GlassCard>
  );
};
```

---

## Validation Steps

After implementing each phase:

### 1. Database Validation
```bash
# Apply migrations
npx supabase migration up --local

# Test RPC functions
npx supabase db diff --local
```

### 2. API Contract Validation
```bash
# Test save/unsave endpoint
curl -X PUT http://localhost:3000/api/signals/[signal-id]/save \
  -H "Authorization: Bearer [token]"
# Should return: { "saved": true }
```

### 3. Dashboard Stats Validation
1. Open dashboard at `/dashboard`
2. Check Network tab for `/api/signals/analytics` call
3. Verify stats update from real data

### 4. Activity Feed Validation
1. Create a new signal via n8n webhook
2. Check dashboard shows new activity
3. Verify real-time updates

### 5. Performance Validation
```bash
# Run TypeScript check
npx pnpm type-check

# Build project
npx pnpm build

# Check for any errors
```

## Summary of Changes

1. **Database**: Added 3 missing RPC functions + analytics history + activity feed
2. **API**: Fixed save/unsave response format
3. **Services**: Replaced mock data with real EODHD API calls
4. **Hooks**: Connected dashboard stats to analytics endpoint
5. **UI**: Implemented real activity feed with database backing

Total files changed: 12
New files created: 5
Database migrations: 3

This implementation guide provides a complete path to production readiness with real data throughout the application.